\documentclass[17pt, fleqn]{beamer}
\usepackage{default}
\usetheme{default}
% Copenhagen, Madrid would also be possibilities.
% \setbeamercovered{transparent}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,lmodern}

\usepackage{tikzit}
\input{presentation_style_file.tikzstyles}
\graphicspath{{graphics/}}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{multirow} % for tables

\title[]{Masterarbeit}
\author[]{Daniel Siemmeister}
\date[]{2022 - 07 - 07}

% begin document
\begin{document}

\begin{frame}[plain]
    \titlepage    
\end{frame}

\begin{frame}{Titel der Arbeit}
\centering
\large{Erprobung unterschiedlicher Machine Learning Ansätze für die Vorhersage der Prüfungsaktivität von Studierenden}
\end{frame}

\begin{frame}
    Wie viele prüfungsaktive Studierende gibt es in drei Jahren? \\[1cm]
    \pause
    Ansätze des LQM \\[1cm]
    \pause
    Prädiktion der Wahrscheinlichkeit, in drei Jahren prüfungsaktiv zu sein - ohne konkrete Klassifizierung
\end{frame}

\begin{frame}{Machine Learning}
    \small{
    $ \mathcal{X} \dots \text{Menge der Inputdaten} $ \\[0.2cm]
    $ \mathcal{Y} \dots \text{Menge der Outputdaten} $ \\[0.2cm]
    $ \mathcal{D_{\mathbf{X}}} \dots \text{Verteilung über } \mathcal{X} $ \\[0.2cm]
    $ f(\cdot) \dots \text{mit } Y = f(\mathbf{X}) + \epsilon $ \\[0.2cm]
    $ S = \{ (\mathbf{x}_1, y_1), \dots , (\mathbf{x}_n, y_n) \} \text{ mit n Datenpunkten} $ \\[0.2cm]
    $ \mathcal{D} \dots \text{gemeinsame Verteilung von } (\mathbf{X}, Y) $ \\[0.2cm]
    }
\end{frame}

\begin{frame}{Machine Learning}
    \small{
    $ \mathcal{H} = \{ h( \cdot, \mathbf{w}) | \mathbf{w} \in \mathbf{W} \} $ \\[0.2cm]
    $ \mathcal{A} \dots \text{Algorithmus mit } h_S = \mathcal{A}(S) $ \\[0.2cm]
    $ l : \mathcal{H} \times \mathcal{Z} \rightarrow \mathbb{R}_+ \dots \text{loss-Funktion, wobei } \mathcal{Z} = \mathcal{X} \times \mathcal{Y} $ \\[0.2cm]
    $ L_D(\mathcal{A}) = \mathbb{E}[l(\mathcal{A}(S), (\mathbf{X}, Y)) ] \dots \text{wahre Risikofunktion} $ \\[0.2cm]
    $ L_S(h_S) = \frac{1}{n} \sum_{i=1}^n l(h_S, (\mathbf{x}_i, y_i)) \dots \text{empirische Risikofunktion} $ \\[0.2cm]
    }
\end{frame}

\begin{frame}{Machine Learning}
    \small{
        mit $ \epsilon $ wird Verteilung von $ \mathcal{D}_{Y|\mathbf{X}} $ festgelgt \\ [0.2cm]
        Parameter von $ \mathcal{D}_{Y|\mathbf{X}} $ soll mittels $ h_S $ approximiert werden \\ [0.2cm]
        Sinvolle Wahlen: Erwartungswert, Median \\ [0.2cm]
        loss-Funktion entscheidet darüber, welcher Parameter approximiert wird
        \begin{itemize}
            \item $l(h_S, (\mathbf{X}, Y)) = (Y - h_S(\mathbf{X}))^2 $ approximiert $\mathbb{E}[Y|\mathbf{X}] $
            \item $l(h_S, (\mathbf{X}, Y)) = |Y- h_S(\mathbf{X})| $ approximiert $m(Y|\mathbf{X}) $ (Median) 
        \end{itemize}
    }
\end{frame}

\begin{frame}{Machine Learning}
    \small{
        erwarteter Output: $ \bar{y}(\mathbf{x}) = \mathbb{E}[Y|\mathbf{X} = \mathbf{x}] $ \\[0.5cm]
        erwartete Vorhersagefunktion: $ \bar{h} = \mathbb{E}[\mathcal{A}(S)] = \int_{\mathbb{R}^{(d+1)n}} h_s p_S(s)  \,ds $ \\[0.5cm]
        $ \mathcal{L}_{\mathcal{D}}(\mathcal{A}) = \mathbb{E}[(h_S(\mathbf{\mathbf{X}})-Y)^2] $ wird zu \\[0.5cm]
        \footnotesize{$ \underbrace{\mathbb{E}[(h_S(\mathbf{X})- \bar{h}(\mathbf{X}))^2]}_{\text{Variance}}+\underbrace{\mathbb{E}[(\bar{h}(\mathbf{X})-\bar{y}(\mathbf{X}))^2]}_{\text{Bias}^2} + \underbrace{\mathbb{E}[(\bar{y}(\mathbf{X})-Y)^2]}_{\text{Noise}} $
    }}
    
\end{frame}


\begin{frame}{Problemstellung}
    \begin{scriptsize}
		\tikzfig{problemstellung}
	\end{scriptsize}
    
\end{frame}

\begin{frame}{Relevanz der Problemstellung}
    \begin{figure}[ht]
        
        \begin{subfigure}{0.49\textwidth}
            
            \includegraphics[width = 1\textwidth]{pad2.pdf}
        \end{subfigure}
        \begin{subfigure}{0.49\textwidth}
            
            \includegraphics[width = 1\textwidth]{bwl2.pdf}
        \end{subfigure}
        \begin{subfigure}{0.49\textwidth}
           
            \includegraphics[width = 1\textwidth]{jus2.pdf}
        \end{subfigure}
        \begin{subfigure}{0.49\textwidth}
            
            \includegraphics[width = 1\textwidth]{ges2.pdf}
        \end{subfigure}
            
    \end{figure}
    
\end{frame}

\begin{frame}
    Problem 1: \\
    Schätzung der prüfungsaktiven Studierenden, von den bereits Anzahl und Merkmalskombinationen vorhanden sind \\[1cm]

    \pause

    Problem 2: \\
    Schätzung der prüfungsaktiven Studierenden, von denen weder Anzahl noch Merkmalskombinationen vorhanden sind    
\end{frame}

\begin{frame}{Herangehensweise Problem 1}
    \begin{itemize}
        \item Regression der ECTS \\[1cm]
        \pause
        \item Markov Ketten Modell \\[1cm]
        \pause
        \item Schätzung der Wahrscheinlichkeit aktiv zu sein, ohne zu klassifizieren
    \end{itemize}
    
\end{frame}

\begin{frame}{Ergebnisse für Problem 1 Ansatz 1}
    \scriptsize{
    \begin{table}[ht]
        \begin{tabular}{ p{2cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1cm} }
          Metrik &               & lineare Regression & Random Forest  & SVM            & KNN (ohne CV) \\
          \hline
          \multirow{2}{3em}{RMSE (Crossvalidation)}
                 & 1 Jahr        & $18.7 \pm 0.2$     & $19.2 \pm 0.3$ & $19.7 \pm 0.4$ & $18.72$       \\
                 & $\geq$ 2 Jahre & $16.8 \pm 0.2$     & $15.4 \pm 0.2$ & $19.2 \pm 0.3$ & $14.8$        \\
      
          \hline
          \multirow{2}{3em}{MAE (Trainingsdaten)}
                 & 1 Jahr        & $15.6$             & $15.9$         & $15.9$         & $14.5$        \\
                 & $\geq$ 2 Jahre & $13.3$             & $11.7$         & $16.2$         & $10.4$        \\
      
          \hline
          \multirow{2}{3em}{R2-Score}
                 & 1 Jahr        & $0.06$             & $-.01$         & $-0.05$        & $0.06$        \\
                 & $\geq$ 2 Jahre & $0.38$             & $0.48$         & $0.17$         & $0.52$        \\
      
          \hline
          \multirow{2}{3em}{$\%$ Accurancy}
                 & 1 Jahr        & $61$               & $61$           & $60$           & $63$          \\
                 & $\geq$ 2 Jahre & $80$               & $78$           & $66$           & $80$          \\
      
          \hline
        \end{tabular}
      \end{table}
    }
    
\end{frame}

\begin{frame}{Ergebnisse für Problem 1 Ansatz 2}
    \begin{scriptsize}
		\tikzfig{fig1}
	\end{scriptsize}
\end{frame}

\begin{frame}{Ergebnisse für Problem 1 Ansatz 2}
    \footnotesize{
    $\left[ \begin{array}{rrrr}  0.05 & 0.19 & 0.53 & 0.23  \end{array}\right]$,
    $\left[ \begin{array}{rrrr} 0 & 0 & 0 & 0 \\  0 & 0 & 0 & 0 \\ 0.02 & 0.13 & 0.79 & 0.07 \\ 0.02 & 0.49 & 0.19 & 0.29 \end{array}\right]$,
    $\left[ \begin{array}{rrrr} 0 & 0 & 0 & 0 \\  0 & 0 & 0 & 0 \\ 0.01 & 0.05  & 0.82  & 0.13 \\ 0.01 & 0.46 & 0.24 & 0.29 \end{array}\right]$,
    $\left[ \begin{array}{rrrr} 0 & 0 & 0 & 0 \\  0 & 0 & 0 & 0 \\ 0.05 & 0.01 & 0.83 & 0.11\\ 0.00& 0.18 & 0.25 & 0.50\end{array}\right]$,
    $\left[ \begin{array}{rrrr} 0 & 0 & 0 & 0 \\  0 & 0 & 0 & 0 \\ 0.15& 0.02& 0.71& 0.12\\ 0.03& 0.27& 0.28& 0.42 \end{array}\right]$.
    }
\end{frame}



\begin{frame}{Ergebnisse für Problem 1 Ansatz 3}
    \scriptsize{
    \begin{table}[ht]
        \begin{tabular}{ p{1.5cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1cm} }
                         &                  & log. Reg.                                  & RF                                         & SVM                                        & KNN                                        \\
          \hline
          \multirow{2}{3em}{1 Jahr}
                         & Predicted        & 129.39                                     & 128.17                                     & 128.84                                     & 129.29                                     \\
                         & Real             & 129                                        & 129                                        & 129                                        & 129                                        \\
      
          \multirow{2}{2.5cm}{$\geq$ 2 Jahre}
                         & Predicted        & 121.25                                     & 117.46                                     & 120.59                                     & 120.9                                      \\
                         & Real             & 121                                        & 121                                        & 121                                        & 121                                        \\
          \hline
          
          1 Jahr         & CV Scores        & 0.63 $\pm$ 0.00                            & 0.62 $\pm$ 0.01                            & 0.63 $\pm$ 0.02                            & 0.62 $\pm$ 0.01                            \\
          $\geq$ 2 Jahre & CV Scores        & 0.70 $\pm$ 0.01                            & 0.73 $\pm$ 0.01                            & 0.68 $\pm$ 0.01                            & 0.72 $\pm$ 0.01                            \\
      
          \hline
        \end{tabular}
      \end{table}
    }
\end{frame}

\begin{frame}{Ergebnisse für Problem 1}
    \small{
    \begin{itemize}
        \item[\textcolor{red}{X}] Ansatz 1 funktioniert nicht - zu große Fehler bei Schätzung der ECTS \pause
        \item[\textcolor{red}{X}] Ansatz 2 benötigt mehr Daten, um ihn seriös zu erproben \pause
        \item[\textcolor{green}{\checkmark}] Ansatz 3 funktioniert auf kleinem Datensatz (sehr!) gut - man benötigt mehr Daten um ihn noch besser zu erproben
    \end{itemize}
    }
    
\end{frame}

\begin{frame}{Herangehensweise Problem 2}
    \begin{itemize}
        \item Schätzung der Anzahl der Studierenden mit gleicher Merkmalskombination wie im Jahr zuvor \\[1cm]
        \pause
        \item Clustering der Studierenden und anschließende Schätzung der Anzahl nach Cluster
    \end{itemize}
    
\end{frame}

\begin{frame}{Ergebnisse für Problem 2}
    \scriptsize{
    \begin{table}[ht]
        \begin{tabular}{ p{1cm} p{0.5cm} p{2cm} p{2.5cm} p{2cm} }
          Zeitspanne der Sch\"atzung &      & Prediction reale Daten & Prediction dummy Daten (Anzahl gegeben) & tats\"achliche Anzahl \\
          \hline
          \multirow{2}{3em}{1 Jahr}
                                     & 2016 & 1118                   & 1105                                    & 1092                  \\
                                     & 2017 & 1000                   & 984                                     & 973                   \\
          \hline
          \multirow{2}{4em}{2 Jahre}
                                     & 2016 & 867                    & 878                                     & 819                   \\
                                     & 2017 & 769                    & 769                                     & 721                   \\
      
          \hline
        \end{tabular}
      \end{table}
    } \pause
    \small{
    \begin{itemize}
        \item[\textcolor{orange}{$\sim$}] Legitimation von Ansatz 1 für Problem 2 \pause
        \item[\textcolor{orange}{$\sim$}] Zu wenige Daten vorhanden, um Ansatz 2 für Problem 2 seriös zu erproben
    \end{itemize}
    }
\end{frame}

\begin{frame}{Beiträge}
    Klare Darstellung der Problemstellung \\[1cm]
    \pause
    Erprobung unterschiedlicher Ansätze \\[1cm]
    \pause
    Machine Learning Ansatz für Problem 1, der gute Ergebnisse liefert \\[1cm]
    \pause
    Notwendigkeit von mehr Daten, um Ansätze weiter zu Erproben
    
\end{frame}






\end{document}