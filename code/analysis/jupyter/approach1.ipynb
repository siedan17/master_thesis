{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babe76b4",
   "metadata": {},
   "source": [
    "# APPROACH 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f033b8f",
   "metadata": {},
   "source": [
    "## Import & Globals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eecf32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random as rd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "raw_data_folder = os.path.abspath('/home/siedan/programming/masterarbeit/code/analysis/raw_data')\n",
    "\n",
    "def load_df(name):\n",
    "    return pd.read_csv(os.path.join(raw_data_folder, name))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = load_df('adapted_data.csv').drop(['Unnamed: 0'], axis =1)\n",
    "\n",
    "features_year1 = ['styria_dummy', 'not_styria_dummy', 'germany_dummy',\n",
    "                  'num_parallel_studies', 'cum_ects_pos_before', 'years_since_matura', 'firstGen',\n",
    "                  'geschlecht', 'AHS_dummy', 'BHS_dummy', 'ausland_vorbildung_dummy',\n",
    "                  'sonstige_vorbildung_dummy', 'jus_dummy', 'bwl_dummy',\n",
    "                  'delayed_dummy', 'ECTS_year', 'active_dummy']\n",
    "\n",
    "features_years = ['Studienjahr', 'styria_dummy', 'not_styria_dummy', 'germany_dummy',\n",
    "                  'num_parallel_studies', 'cum_ects_pos_before', 'avgECTS_sem_before', 'ects_year_before',\n",
    "                  'full_duration_sem_before', 'geschlecht', 'years_since_matura', 'firstGen', 'AHS_dummy',\n",
    "                  'BHS_dummy', 'ausland_vorbildung_dummy', 'sonstige_vorbildung_dummy',\n",
    "                  'delayed_dummy', 'jus_dummy', 'bwl_dummy',\n",
    "                  'ECTS_year', 'active_dummy']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e4735",
   "metadata": {},
   "source": [
    "## Algorithms for transition:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a771e6e3",
   "metadata": {},
   "source": [
    "### Help Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c59726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active(df_, prediction):\n",
    "    df = df_.copy(deep = True)\n",
    "    df.reset_index(drop = True)\n",
    "    if len(df) == len(prediction):\n",
    "        new_column = []\n",
    "        for i in range(len(prediction)):\n",
    "            if prediction[i] >= 16:\n",
    "#             a = rd.random()\n",
    "#             if a > 0.1:\n",
    "                new_column.append(1)\n",
    "            else:\n",
    "                new_column.append(0)\n",
    "        df.insert(len(df.columns), 'active_predicted', new_column, allow_duplicates = True)\n",
    "        df.insert(len(df.columns), 'ECTS_predicted', prediction, allow_duplicates = True)\n",
    "    else:\n",
    "        print('ERROR')\n",
    "    return df\n",
    "\n",
    "    \n",
    "def ratio(df):\n",
    "    ratio = 0\n",
    "    for i in df.index:\n",
    "        if df.loc[i, 'active_dummy'] == df.loc[i, 'active_predicted']:\n",
    "            ratio +=1\n",
    "    ratio = ratio/len(df)\n",
    "    return ratio\n",
    "\n",
    "\n",
    "def display_scores(scores):\n",
    "    print('Scores: ', scores)\n",
    "    print('Mean: ', scores.mean())\n",
    "    print('Standard deviation: ', scores.std())\n",
    "\n",
    "\n",
    "def create_data1(df):\n",
    "    df = df.query('Studienjahr == 1')[features_year1].dropna().reset_index(drop = True).copy(deep = True)\n",
    "    split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.1, random_state = 42)\n",
    "    for train_index, test_index in split.split(df, df['active_dummy']):\n",
    "        df_train = df.loc[train_index, :]\n",
    "        df_test = df.loc[test_index, :]\n",
    "    df_train_copy = df_train.copy(deep = True)\n",
    "    y_train = list(df_train['ECTS_year'])\n",
    "    y_test = list(df_test['ECTS_year'])\n",
    "    df_train = scaler.fit_transform(df_train.drop(['ECTS_year', 'active_dummy'], axis = 1))\n",
    "    df_test = scaler.fit_transform(df_test.drop(['ECTS_year', 'active_dummy'], axis = 1))\n",
    "    return df_train, y_train, df_test, y_test, df_train_copy\n",
    "\n",
    "def create_data2(df):\n",
    "    df = df.query('Studienjahr > 1')[features_years].dropna().reset_index(drop = True).copy(deep = True)\n",
    "    split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.1, random_state = 42)\n",
    "    for train_index, test_index in split.split(df, df['active_dummy']):\n",
    "        df_train = df.loc[train_index, :]\n",
    "        df_test = df.loc[test_index, :]\n",
    "    df_train_copy = df_train.copy(deep = True)\n",
    "    y_train = list(df_train['ECTS_year'])\n",
    "    y_test = list(df_test['ECTS_year'])\n",
    "    df_train = scaler.fit_transform(df_train.drop(['ECTS_year', 'active_dummy'], axis = 1))\n",
    "    df_test = scaler.fit_transform(df_test.drop(['ECTS_year', 'active_dummy'], axis = 1))\n",
    "    return df_train, y_train, df_test, y_test, df_train_copy\n",
    "\n",
    "\n",
    "def training_regression(df_train, y_train, df_train_copy, model): # df_train is already scaled!\n",
    "    model = sklearn.base.clone(model)\n",
    "    model.fit(df_train, y_train)\n",
    "    \n",
    "    predictions = cross_val_predict(model, df_train, y_train, cv=3)\n",
    "    rmse = np.sqrt(mean_squared_error(y_train, predictions))\n",
    "    mae = mean_absolute_error(y_train, predictions)\n",
    "    R_squared = r2_score(y_train, predictions)\n",
    "    \n",
    "    print('RMSE = ' + str(rmse))\n",
    "    print('MAE = ' + str(mae))\n",
    "    print('R2_score = ' + str(R_squared))\n",
    "    print('----------')\n",
    "    df_new = active(df_train_copy, predictions)\n",
    "    print('Ratio = ' + str(ratio(df_new)))\n",
    "    scores = cross_val_score(model, df_train, y_train, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    display_scores(rmse_scores)\n",
    "    print('##########')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b632d74",
   "metadata": {},
   "source": [
    "### Data Generating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc1ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year 1 - 2:\n",
    "df1_train, y1_train, df1_test, y1_test, df1_train_copy = create_data1(df)\n",
    "\n",
    "# Year 2 -:\n",
    "\n",
    "df2_train, y2_train, df2_test, y2_test, df2_train_copy = create_data2(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10bdaa",
   "metadata": {},
   "source": [
    "### Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e6ec2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 18.77059116012316\n",
      "MAE = 15.568643160739695\n",
      "R2_score = 0.06143971832539552\n",
      "----------\n",
      "Ratio = 0.614751552795031\n",
      "Scores:  [18.56621145 18.69723028 18.77246858 19.1007684  18.70248712]\n",
      "Mean:  18.767833167684124\n",
      "Standard deviation:  0.17931734237340144\n",
      "##########\n",
      "RMSE = 16.792785050149078\n",
      "MAE = 13.304248972681252\n",
      "R2_score = 0.3841822963766356\n",
      "----------\n",
      "Ratio = 0.8015368701049209\n",
      "Scores:  [16.68162667 17.15400082 16.62796605 16.58746386 16.84936219]\n",
      "Mean:  16.780083917667913\n",
      "Standard deviation:  0.2071470468154349\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Year 1 - 2:\n",
    "\n",
    "reg1 = training_regression(df1_train, y1_train, df1_train_copy, lin_reg)\n",
    "\n",
    "# Year 2 -:\n",
    "\n",
    "reg2 = training_regression(df2_train, y2_train, df2_train_copy, lin_reg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb6613",
   "metadata": {},
   "source": [
    "### Support Vector Machines:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da49095",
   "metadata": {},
   "source": [
    "### Hyperparameters:\n",
    "- kernel: linear, polynomial, gaussian or sigmoid. Uses the kernel trick to compute additional features.\n",
    "\n",
    "- gamma: if the model ist underfitting I should increase it. If the model is overfitting I should decrease it.\n",
    " \n",
    "- C: is a parameter which controls the margin violations. Higher more violations, but generalizes better.\n",
    "\n",
    "- epsilion (only for regression): controls the width of the \"street\". Similar to C. However, I don't get the difference. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "886feb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 19.89854674184339\n",
      "MAE = 15.890890266276436\n",
      "R2_score = -0.05474867822405449\n",
      "----------\n",
      "Ratio = 0.595807453416149\n",
      "Scores:  [19.31515662 19.83359328 19.73776373 20.31628386 19.35934422]\n",
      "Mean:  19.712428343181685\n",
      "Standard deviation:  0.36399382930308655\n",
      "##########\n",
      "RMSE = 19.490492903716163\n",
      "MAE = 16.17574093496439\n",
      "R2_score = 0.17043130189145927\n",
      "----------\n",
      "Ratio = 0.6610758090734447\n",
      "Scores:  [19.52782288 19.26343423 19.33188666 18.74589554 19.26255786]\n",
      "Mean:  19.22631943389953\n",
      "Standard deviation:  0.25905467236977164\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "svm_reg = SVR(kernel = 'rbf', gamma = 10, C = 100, epsilon = 5)\n",
    "\n",
    "# Year 1 - 2:\n",
    "svm1 = training_regression(df1_train, y1_train, df1_train_copy, svm_reg)\n",
    "\n",
    "# Year 2 - :\n",
    "svm2 = training_regression(df2_train, y2_train, df2_train_copy, svm_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0968f74",
   "metadata": {},
   "source": [
    "### Random Forest:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0cda3",
   "metadata": {},
   "source": [
    "### Hyperparameters:\n",
    "- n_estimators: number of Decsiontrees.\n",
    "- max_depths: maximal depth of each tree.\n",
    "- max_leaf_nodes: controls the depths of the trees.\n",
    "- criterion: mse or msa. function to measure the quality of the split.\n",
    "- max_samples: (bootstrap = True) How many samples from df_train are drawn to train each regressor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39916a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 19.438566614408373\n",
      "MAE = 15.858175866688264\n",
      "R2_score = -0.006548590666372922\n",
      "----------\n",
      "Ratio = 0.6090062111801242\n",
      "Scores:  [18.9070478  19.23735648 19.27033251 19.6753801  19.04821882]\n",
      "Mean:  19.227667140504884\n",
      "Standard deviation:  0.25975356634470487\n",
      "##########\n",
      "RMSE = 15.531487866422312\n",
      "MAE = 11.585475281884428\n",
      "R2_score = 0.4732156849685838\n",
      "----------\n",
      "Ratio = 0.784912073296882\n",
      "Scores:  [15.82945108 15.41015298 15.48647936 15.16328423 15.3851936 ]\n",
      "Mean:  15.454912250397143\n",
      "Standard deviation:  0.2159568485062251\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "forest_reg = RandomForestRegressor(\n",
    "#             n_estimators = 500, max_depth = 150, max_leaf_nodes = 100, criterion = 'mae',\n",
    "#             max_samples = 500\n",
    "        )\n",
    "\n",
    "forest1 = training_regression(df1_train, y1_train, df1_train_copy, forest_reg)\n",
    "\n",
    "# Year 2 -:\n",
    "forest2 = training_regression(df2_train, y2_train, df2_train_copy, forest_reg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da3d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1762e9",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd7313",
   "metadata": {},
   "source": [
    "- epochs: So oft wird ueber alle Trainingsdaten iteriert.\n",
    "- batch_size: So gross ist ein batch fuer den ein Gradient berechnet wird. (Keine Ahnung wie das mit SGD geht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ea008d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_ann_regression(df_train, y_train, df_train_copy):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(60, activation = 'relu', input_shape = df_train.shape[1:]),\n",
    "        keras.layers.Dense(40, activation = 'relu'),\n",
    "        keras.layers.Dense(20, activation = 'relu'),\n",
    "        keras.layers.Dense(1, activation = 'relu')\n",
    "    ])\n",
    "    model.compile(loss = 'huber', optimizer = 'sgd')\n",
    "    history = model.fit(df_train, np.array(y_train), epochs = 35, validation_split = 0.1)\n",
    "    \n",
    "    predictions = model.predict(df_train)\n",
    "    rmse = np.sqrt(mean_squared_error(y_train, predictions))\n",
    "    mae = mean_absolute_error(y_train, predictions)\n",
    "    R_squared = r2_score(y_train, predictions)\n",
    "    \n",
    "    print('RMSE = ' + str(rmse))\n",
    "    print('MAE = ' + str(mae))\n",
    "    print('R2_score = ' + str(R_squared))\n",
    "    print('----------')\n",
    "    df_new = active(df_train_copy, predictions)\n",
    "    print('Ratio = ' + str(ratio(df_new)))\n",
    "    print('##########')\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f21ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "182/182 [==============================] - 1s 2ms/step - loss: 16.3272 - val_loss: 15.0597\n",
      "Epoch 2/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.5081 - val_loss: 15.0185\n",
      "Epoch 3/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.4496 - val_loss: 14.7844\n",
      "Epoch 4/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.3915 - val_loss: 14.6499\n",
      "Epoch 5/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.3315 - val_loss: 14.7452\n",
      "Epoch 6/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.3223 - val_loss: 14.6234\n",
      "Epoch 7/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.2912 - val_loss: 14.5823\n",
      "Epoch 8/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.2380 - val_loss: 15.2007\n",
      "Epoch 9/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.2435 - val_loss: 14.7040\n",
      "Epoch 10/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.2259 - val_loss: 14.5768\n",
      "Epoch 11/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.2048 - val_loss: 14.5702\n",
      "Epoch 12/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.2067 - val_loss: 14.7426\n",
      "Epoch 13/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.1963 - val_loss: 14.5595\n",
      "Epoch 14/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.1866 - val_loss: 14.6074\n",
      "Epoch 15/35\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 14.1544 - val_loss: 14.5164\n",
      "Epoch 16/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.1539 - val_loss: 14.6318\n",
      "Epoch 17/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.1469 - val_loss: 14.5868\n",
      "Epoch 18/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.1351 - val_loss: 14.5711\n",
      "Epoch 19/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.1290 - val_loss: 14.5343\n",
      "Epoch 20/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.1416 - val_loss: 14.4255\n",
      "Epoch 21/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.1431 - val_loss: 14.4623\n",
      "Epoch 22/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.1184 - val_loss: 14.5603\n",
      "Epoch 23/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.1065 - val_loss: 14.3585\n",
      "Epoch 24/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.0844 - val_loss: 14.4460\n",
      "Epoch 25/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.0944 - val_loss: 14.3877\n",
      "Epoch 26/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.0794 - val_loss: 14.5585\n",
      "Epoch 27/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.0910 - val_loss: 14.3336\n",
      "Epoch 28/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.0754 - val_loss: 14.4260\n",
      "Epoch 29/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.0569 - val_loss: 14.6068\n",
      "Epoch 30/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.0850 - val_loss: 14.4349\n",
      "Epoch 31/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.0588 - val_loss: 14.5932\n",
      "Epoch 32/35\n",
      "182/182 [==============================] - 0s 2ms/step - loss: 14.0654 - val_loss: 14.3452\n",
      "Epoch 33/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.0355 - val_loss: 14.5023\n",
      "Epoch 34/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.0533 - val_loss: 14.4760\n",
      "Epoch 35/35\n",
      "182/182 [==============================] - 0s 1ms/step - loss: 14.0341 - val_loss: 14.3381\n",
      "RMSE = 19.050443593632327\n",
      "MAE = 14.505278963958903\n",
      "R2_score = 0.033244934765009226\n",
      "----------\n",
      "Ratio = 0.6225155279503105\n",
      "##########\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann1, history1 = training_ann_regression(df1_train, y1_train, df1_train_copy)\n",
    "\n",
    "pd.DataFrame(history1.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae46210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "381/381 [==============================] - 1s 1ms/step - loss: 15.0068 - val_loss: 11.7875\n",
      "Epoch 2/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 11.6248 - val_loss: 11.1955\n",
      "Epoch 3/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 11.1071 - val_loss: 11.0603\n",
      "Epoch 4/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.8421 - val_loss: 10.8316\n",
      "Epoch 5/35\n",
      "381/381 [==============================] - 1s 1ms/step - loss: 10.6462 - val_loss: 10.6780\n",
      "Epoch 6/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.5687 - val_loss: 10.4739\n",
      "Epoch 7/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.4727 - val_loss: 10.4514\n",
      "Epoch 8/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.4342 - val_loss: 10.4415\n",
      "Epoch 9/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.3846 - val_loss: 10.4651\n",
      "Epoch 10/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.3515 - val_loss: 10.4994\n",
      "Epoch 11/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.3069 - val_loss: 10.5432\n",
      "Epoch 12/35\n",
      "381/381 [==============================] - 1s 1ms/step - loss: 10.2774 - val_loss: 10.4544\n",
      "Epoch 13/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.2691 - val_loss: 10.5636\n",
      "Epoch 14/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.2219 - val_loss: 10.4462\n",
      "Epoch 15/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.2185 - val_loss: 10.6193\n",
      "Epoch 16/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.2016 - val_loss: 10.6163\n",
      "Epoch 17/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.1533 - val_loss: 10.4568\n",
      "Epoch 18/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.1519 - val_loss: 10.6470\n",
      "Epoch 19/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.1251 - val_loss: 10.3907\n",
      "Epoch 20/35\n",
      "381/381 [==============================] - 1s 1ms/step - loss: 10.1133 - val_loss: 10.5063\n",
      "Epoch 21/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.0902 - val_loss: 10.4016\n",
      "Epoch 22/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.0720 - val_loss: 10.4697\n",
      "Epoch 23/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.0384 - val_loss: 10.4099\n",
      "Epoch 24/35\n",
      "381/381 [==============================] - 1s 1ms/step - loss: 10.0350 - val_loss: 10.6704\n",
      "Epoch 25/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.0493 - val_loss: 10.4710\n",
      "Epoch 26/35\n",
      "381/381 [==============================] - 1s 1ms/step - loss: 10.0031 - val_loss: 10.4884\n",
      "Epoch 27/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.0056 - val_loss: 10.4911\n",
      "Epoch 28/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 10.0089 - val_loss: 10.3614\n",
      "Epoch 29/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 9.9938 - val_loss: 10.3626\n",
      "Epoch 30/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 9.9658 - val_loss: 10.4734\n",
      "Epoch 31/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 9.9835 - val_loss: 10.3111\n",
      "Epoch 32/35\n",
      "381/381 [==============================] - 1s 1ms/step - loss: 9.9453 - val_loss: 10.3134\n",
      "Epoch 33/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 9.9282 - val_loss: 10.3692\n",
      "Epoch 34/35\n",
      "381/381 [==============================] - 1s 2ms/step - loss: 9.9380 - val_loss: 10.3624\n",
      "Epoch 35/35\n",
      "381/381 [==============================] - 0s 1ms/step - loss: 9.9029 - val_loss: 10.2887\n",
      "RMSE = 14.544868104768353\n",
      "MAE = 10.200270494542906\n",
      "R2_score = 0.5380166894940415\n",
      "----------\n",
      "Ratio = 0.802127973991429\n",
      "##########\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann2, history2 = training_ann_regression(df2_train, y2_train, df2_train_copy)\n",
    "\n",
    "pd.DataFrame(history2.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580a948",
   "metadata": {},
   "source": [
    "# Simulation of Model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08533693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pretty = load_df('df_pretty.csv').drop(['Unnamed: 0'], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52ab1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_pretty.groupby('matrikel_num')\n",
    "list_of_students = [] # list von df's, wobei jedes df einen Studenten oder eine Studentin ueber mehrere Jahre hinweg beschreibt.\n",
    "\n",
    "for i in df_pretty['matrikel_num'].drop_duplicates():\n",
    "    list_of_students.append(groups.get_group(i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2ed7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ects_year_before</th>\n",
       "      <th>ects_predicted</th>\n",
       "      <th>ECTS_year</th>\n",
       "      <th>SWS_year</th>\n",
       "      <th>active_predicted</th>\n",
       "      <th>active_dummy</th>\n",
       "      <th>avgECTS_sem_before</th>\n",
       "      <th>full_duration_sem_before</th>\n",
       "      <th>cum_ects_pos_before</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Padagogik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Padagogik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Padagogik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>30.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>Padagogik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15.422166</td>\n",
       "      <td>65.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Padagogik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.422166</td>\n",
       "      <td>23.015109</td>\n",
       "      <td>65.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.711083</td>\n",
       "      <td>2</td>\n",
       "      <td>15.422166</td>\n",
       "      <td>Padagogik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.015109</td>\n",
       "      <td>23.015109</td>\n",
       "      <td>65.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.609319</td>\n",
       "      <td>4</td>\n",
       "      <td>38.437275</td>\n",
       "      <td>Padagogik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.015109</td>\n",
       "      <td>23.015109</td>\n",
       "      <td>65.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.242064</td>\n",
       "      <td>6</td>\n",
       "      <td>61.452384</td>\n",
       "      <td>Padagogik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ects_year_before ects_predicted ECTS_year SWS_year active_predicted  \\\n",
       "1085              NaN            NaN      65.0     36.0              NaN   \n",
       "1086             65.0            NaN      55.0     24.0              NaN   \n",
       "1087             55.0            NaN      32.0     16.0              NaN   \n",
       "1088             32.0            NaN       3.0      2.0              NaN   \n",
       "0                   0      15.422166      65.0     36.0                0   \n",
       "1           15.422166      23.015109      65.0     36.0                1   \n",
       "2           23.015109      23.015109      65.0     36.0                1   \n",
       "3           23.015109      23.015109      65.0     36.0                1   \n",
       "\n",
       "     active_dummy avgECTS_sem_before full_duration_sem_before  \\\n",
       "1085            1                0.0                      0.0   \n",
       "1086            1               32.5                      2.0   \n",
       "1087            1               30.0                      4.0   \n",
       "1088            1               30.4                      5.0   \n",
       "0               1                0.0                      0.0   \n",
       "1               1           7.711083                        2   \n",
       "2               1           9.609319                        4   \n",
       "3               1          10.242064                        6   \n",
       "\n",
       "     cum_ects_pos_before    subject  \n",
       "1085                 0.0  Padagogik  \n",
       "1086                65.0  Padagogik  \n",
       "1087               120.0  Padagogik  \n",
       "1088               152.0  Padagogik  \n",
       "0                    0.0  Padagogik  \n",
       "1              15.422166  Padagogik  \n",
       "2              38.437275  Padagogik  \n",
       "3              61.452384  Padagogik  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [svm1, svm2]\n",
    "features = [features_year1[:-2], features_years[:-2]]\n",
    "\n",
    "test_student = list_of_students[257]\n",
    "\n",
    "\n",
    "def update(input_series):\n",
    "    series = input_series.copy(deep = True)\n",
    "    series['ects_year_before'] = series['ects_predicted']\n",
    "    series['cum_ects_pos_before'] += series['ects_predicted']\n",
    "    if series['Studienjahr'] == 1:\n",
    "        series['full_duration_sem_before'] = 2\n",
    "    else:\n",
    "        series['full_duration_sem_before'] += 2\n",
    "    series['avgECTS_sem_before'] = series['cum_ects_pos_before']/series['full_duration_sem_before']\n",
    "    series['Studienjahr'] += 1\n",
    "    return series\n",
    "\n",
    "def predict(input_student, predictors, features):\n",
    "    student = input_student.copy(deep = True)\n",
    "    if student['Studienjahr'] == 1:\n",
    "        predictor = predictors[0]\n",
    "        feature = features[0]\n",
    "    else:\n",
    "        predictor = predictors[1]\n",
    "        feature = features[1]\n",
    "    \n",
    "    student['ects_predicted'] = float(predictor.predict(pd.DataFrame(student[feature]).T))\n",
    "    \n",
    "    if student['ects_predicted'] >= 16:\n",
    "        student['active_predicted'] = 1\n",
    "    else:\n",
    "        student['active_predicted'] = 0\n",
    "    return student\n",
    "\n",
    "\n",
    "def model_student(df, predictors, features):\n",
    "    n_years = len(df)\n",
    "    student = df.iloc[0].fillna(0) # Series object # fillna kann Fehler erzeugen!\n",
    "    list_of_years = [] # initialisiere Liste der Jahre. Erster Eintrag soll dann erstes Jahr mit predicteten ECTS sein.\n",
    "    \n",
    "    for i in range(n_years):\n",
    "        new_student = predict(student, predictors, features).copy(deep = True)\n",
    "        \n",
    "        list_of_years.append(new_student)\n",
    "        \n",
    "        student = update(list_of_years[-1])\n",
    "        \n",
    "    new_df = list_of_years[0].to_frame().T\n",
    "    \n",
    "    for year in list_of_years[1:]:\n",
    "        new_df = new_df.append(year.to_frame().T)\n",
    "    \n",
    "    return new_df.reset_index(drop = True)\n",
    "   \n",
    "    \n",
    "test = model_student(test_student, predictors, features)\n",
    "test_student = test_student.append(test)[['ects_year_before', 'ects_predicted', 'ECTS_year', 'SWS_year',\n",
    "                           'active_predicted', 'active_dummy', 'avgECTS_sem_before', 'full_duration_sem_before',\n",
    "                           'cum_ects_pos_before','subject']]\n",
    "test_student\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d002f60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = list_of_students[:500]\n",
    "count = 0\n",
    "for student in test_data:\n",
    "    prediction = model_student(student, predictors, features)\n",
    "    student = student.append(prediction).reset_index(drop = True)\n",
    "    if student['active_dummy'][3] == student['active_predicted'][7]:\n",
    "        \n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bff8cbb",
   "metadata": {},
   "source": [
    "Es funktioniert leider nicht, dass man rein nur mit predicteten ECTS über Jahre hinweg weitervorhersagt, ob ein\n",
    "Student oder eine Studentin in ca. 3 Jahren noch prüfungsaktiv ist oder nicht. Es hängt nämlich auch von Abschluss\n",
    "oder Abbruch ab. Weiters sind die Fehlerfortpflanzungen zu groß."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3f372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
