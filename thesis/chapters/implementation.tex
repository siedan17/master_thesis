

\section{Implementierung}
\label{sec:impl}

Alle Algorithmen, Modelle und Auswertungen wurden in der Programmiersprache \textit{Python} \cite{python} implementiert. Die wichtigsten
Bibliotheken f\"ur die allgemeine Entwicklung und Auswertung der Modelle waren
\textit{Jupyter} \cite{jupyter}, \textit{Pandas} \cite{pandas}, \textit{Numpy} \cite{numpy} und \textit{Matplotlib} \cite{plt}.

F\"ur die Implementierung der unterschiedlichen Machine Learning Modelle wurde vor allem die Bibliothek \textit{Scikit-Learn} \cite{sklearn_api} verwendet, welche eine einfache API f\"ur
diese und \"ahnliche Problemstellungen bereitstellt. Weiters kann man die Algorithmen leicht auswerten und auch die Hyperparameter optimieren.
F\"ur die Implementierung der k\"unstlichen neuronalen Netzwerke wurden \textit{Tensorflow} \cite{tensorflow} und die passende API von \textit{Keras} \cite{keras} verwendet.

Da sich auf Grund der Menge und Komplexit\"at der Daten der Rechenaufwand in Grenzen gehalten hat, sind alle Modelle auf einem
herk\"ommlichen Computer implementiert und ausgewertet worden.

Alle verwendeten Merkmale wurden standardisiert. Das bedeutet, dass sie jeweils einen empirischen Erwartungswert
von 0, und eine empirische Standardabweichung von 1 haben. Nominale Dateneintr\"age wurden mittels des Verfahrens \textit{One-Hot-Encoding} auf mehrere Variablen
aufgeteilt, welche nur die Werte 0 oder 1 annehmen k\"onnen.

One-Hot-Encoding bedeutet, dass ein nominales Merkmal mit $m$ Klassen in $m-1$ neue Merkmale umcodiert wird. Danach ist jenes Merkmal, welches
der Klasse enspricht in der das Beispiel zuvor war, mit 1 codiert und die anderen neuen Merkmale mit 0. Sollte das Beispiel zuvor in der Klasse, f\"ur die
es kein neues Merkmal gibt, gewesen sein, so entspricht es der Kodierung, dass alle neuen Merkmale 0 sind \cite[Seite 67]{handson}.

F\"ur das Training der Machine Learning Algorithmen wird der von den Anpassungen \"ubrig gebliebene Datensatz
in \textit{Trainigsdaten}, in \textit{Testdaten} und gegebenenfalls in \textit{Validierungsdaten} unterteilt.
Diese Unterteilung wurde so durchgef\"uhrt, dass die jeweiligen Datens\"atze pseudo-randomisiert zusammengestellt wurden,
und auch der Anteil an pr\"ufungsaktiven Studierenden \"uberall gleich ist. Diesen Vorgang nennt man \textit{Stratifizierung} \cite[Seite 53]{handson}. Zus\"atzlich wurde bei der Auswertung des Trainings der
Algorithmen \gls{CV} verwendet.

Crossvalidation bedeuted, dass der Trainingsdatensatz in $k$ gleich m\"achtige Mengen zerteilt wird, die zuf\"allig gebildet werden.
Anschlie{\ss}end wird das Modell $k$-mal trainiert, wobei immer eine Menge ausgelassen wird, auf der das Modell danach validiert wird. Somit bekommt man mehrere Validierungswerte
und sieht auch deren Verteilung \cite[Seiten 31 und 32]{handson}.

Um die Machine Learning Modelle zu erproben sowie die besten auszuw\"ahlen und sp\"ater in den \"ubergeordneten Ans\"atzen zu verwenden,
die dann eine Sch\"atzung der pr\"ufungsaktiven Studierenden ergibt, wurde wie folgt vorgegangen: Zuerst wurden die Daten auf Vollst\"andigkeit gepr√ºft und neue
Merkmale aus bereits vorhandenen Merkmalen berechnet. Hier wurde auch entschieden, ob Merkmale verwendet oder verworfen wurden.
Danach wurden die Daten, je nach Ansatz, nach Studienjahren unterteilt und anschlie{\ss}end wurden die unterschiedlichen Modelle ausprobiert. Hier wurde jenes Modell
beibehalten, welches nach der entsprechenden Metrik am besten abgeschnitten hatte.
Dieses Modell wurde danach in den \"ubergeordneten Ans\"atzen weiterverwendet.

Es wurden bei allen Modellen unterschiedliche Hyperparameter ausprobiert, um f\"ur die Problemstellung den jeweiligen
Algorithmus bestm\"oglich anzupassen. Sie sind in \hyperref[tab:hyperparameter]{Tabelle 2.1} zusammengefasst. Hier handelt es sich
um eine grobe Optimierung der Hyperparameter. F\"ur das Machine Learning Modell, das bei dieser Vorauswertung die besten Werte erzielt hatte,
wurden die Hyperparameter nochmals genauer angepasst. Hierzu wird die Methode des \textit{Grid Search} verwendet.

\begin{table}[ht]
  \caption{\label{tab:hyperparameter} Ausprobierte Hyperparameter}
  \begin{tabular}{ p{4cm}  p{4cm}  p{5cm} }
    \toprule
    Modell                                               & Hyperparameter   & Ausprobierte Werte      \\
    \midrule
    \multirow{4}{7em}{Support Vector Machine}            & kernel           & linear, rbf, polynomial \\
                                                         & gamma            & 5, 10, 15               \\
                                                         & C                & 50, 100, 150            \\
                                                         & epsilon          & 3, 5, 7                 \\
    \midrule
    \multirow{5}{7em}{Random Forest}                     & n\_estimators    & 300, 500                \\
                                                         & max\_depths      & 100, 150 , 200          \\
                                                         & max\_leaf\_nodes & 80, 100, 120            \\
                                                         & criterion        & mse, mae                \\
                                                         & max\_samples     & 100, 500                \\
    \midrule
    \multirow{5}{7em}{K\"unstliches Neuronales Netzwerk} & loss functions   & mse, mae, huber         \\
                                                         & epochs           & 30, 35                  \\
                                                         & activation       & relu, selu              \\
                                                         & num\_layers      & 2, 3, 4                 \\
                                                         & num\_neurons     & 50, 40, 30, 20          \\
    \midrule
    \multirow{2}{7em}{Multiple Linear Regression}        & basis functions  & linear                  \\
                                                         &                  &                         \\
    \midrule
    \multirow{2}{7em}{Multiple Logistic Regression}      & basis functions  & linear                  \\
                                                         &                  &                         \\
                                                         &                  &                         \\
    \bottomrule
  \end{tabular}

\end{table}

Grid Search bedeutet, dass man einen Bereich an diskreten Werten angibt und danach mit jeder Kombination der Werte das Modell neu trainiert und auswertet.
Das ist sehr zeitintensiv und kann somit nur \"uber wenige Kombinationen durchgef\"uhrt werden \cite[Seiten 76 bis 78]{handson}. In dieser Arbeit wurde zuerst Grid Search \"uber eine grobe Einteilung
vorgenommen und anschlie{\ss}end nur das beste Modell einer feineren Grid Search unterzogen.





